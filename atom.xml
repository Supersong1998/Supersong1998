<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://www.sssdoctor.com</id>
    <title>大大大大宋</title>
    <updated>2022-04-07T02:31:55.192Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://www.sssdoctor.com"/>
    <link rel="self" href="https://www.sssdoctor.com/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://www.sssdoctor.com/images/avatar.png</logo>
    <icon>https://www.sssdoctor.com/favicon.ico</icon>
    <rights>All rights reserved 2022, 大大大大宋</rights>
    <entry>
        <title type="html"><![CDATA[tensorflow_keras]]></title>
        <id>https://www.sssdoctor.com/post/tensorflow_keras/</id>
        <link href="https://www.sssdoctor.com/post/tensorflow_keras/">
        </link>
        <updated>2022-04-07T00:42:13.000Z</updated>
        <summary type="html"><![CDATA[<p>import tensorflow as tf<br>
from keras import layers<br>
model=tf.keras.Sequential()<br>
#添加一个64个单元的全连接层，&quot;input_shape&quot;为该层接受输入的数据的维度<br>
##'activation'指定该层用的激活函数</p>
]]></summary>
        <content type="html"><![CDATA[<p>import tensorflow as tf<br>
from keras import layers<br>
model=tf.keras.Sequential()<br>
#添加一个64个单元的全连接层，&quot;input_shape&quot;为该层接受输入的数据的维度<br>
##'activation'指定该层用的激活函数</p>
<!-- more -->
<p>#第一层，输入层<br>
model.add(layers.Dense(64,activation='relu',input_shape=(32,)))<br>
#第二层，隐藏层<br>
model.add(layers.Dense(64,activation='relu'))<br>
#添加一个softmax层作为输出层<br>
model.add(layers.Dense(10,activation='softmax'))<br>
#编译模型，参数包括指定的优化器，学习率，损失函数loss，metics模型的评价函数  其中adam,sgd都是优化器<br>
model.compile(optimizer=tf.keras.optimizers.Adam(0.001),<br>
loss='categorical_crossentropy',<br>
metrics=['accuracy'])<br>
#使用numpy生成随机数作为训练数据<br>
import numpy as np<br>
data=np.random.random((1000,32))#1000行32列<br>
labels=np.random.random((1000,10))<br>
print(data[0])<br>
print(labels[0])</p>
<p>#验证集使用numpy随机生成<br>
val_data=np.random.random((1000,32))<br>
val_labels=np.random.random((1000,10))</p>
<p>model.fit(data,labels,epochs=10,batch_size=50,validation_data=(val_data,val_labels))</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[tensorflow_data]]></title>
        <id>https://www.sssdoctor.com/post/tensorflow_data/</id>
        <link href="https://www.sssdoctor.com/post/tensorflow_data/">
        </link>
        <updated>2022-04-06T12:31:19.000Z</updated>
        <summary type="html"><![CDATA[<p>import tensorflow as tf<br>
import pathlib<br>
#检查tensorflow版本<br>
print(tf.version)</p>
]]></summary>
        <content type="html"><![CDATA[<p>import tensorflow as tf<br>
import pathlib<br>
#检查tensorflow版本<br>
print(tf.version)</p>
<!-- more -->
<p>#获取当前路径<br>
data_root=pathlib.Path.cwd()<br>
print(data_root)</p>
<p>#获取所有图片样本文件的路径并输出：<br>
all_imagine_paths = list(data_root.glob('<em>/</em>/*'))<br>
print(type(all_imagine_paths[0]))</p>
<p>#将对象转换成字符串<br>
all_imagine_paths=[str(path) for path in all_imagine_paths]<br>
print(all_imagine_paths[2])<br>
print(data_root)</p>
<p>#获取图片样本类别的名称，即存放样本的五个文件夹的名称 sorted排序、<br>
label_names=sorted(item.name for item in data_root.glob('<em>/</em>/') if item.is_dir())</p>
<p>#将类别名称转换成为数值型的类标 dict字典 enumerate枚举<br>
label_to_index=dict((name,index) for index,name in enumerate(label_names))</p>
<p>#获取所有图片的类别<br>
all_image_labels = [label_to_index[pathlib.Path(path).parent.name]<br>
for path in all_imagine_paths]<br>
print(label_to_index)</p>
<p>#加载和预处理图片数据<br>
def load_and_preprocessing_image(path):<br>
#读取图片<br>
image=tf.io.read_file(path)<br>
#将jpeg格式的图片解码，得到一个张量（三维的矩阵）<br>
image=tf.image.decode_jpeg(image,channels=3)<br>
#由于数据集中每个图片大小不一样，所以所以将其统一调整为192*192<br>
image=tf.image.resize(image, [192,192])<br>
#对每个像素点的RGB值做归一化处理<br>
image /=255.0</p>
<pre><code>return image
</code></pre>
<p>#构建图片路径的数据集<br>
path_ds=tf.data.Dataset.from_tensor_slices(all_imagine_paths)<br>
#使用autotune自动调节管道参数<br>
AUTOTUNE=tf.data.experimental.AUTOTUNE<br>
#构建图片数据的数据集<br>
image_ds=path_ds.map(load_and_preprocessing_image,num_parallel_calls=AUTOTUNE)<br>
#构建类标的数据集<br>
label_ds=tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels,tf.int64))<br>
#将图片和类标压缩为（图片，类标）对<br>
image_label_ds=tf.data.Dataset.zip((image_ds,label_ds))<br>
print(image_ds)<br>
print(label_ds)<br>
print(image_label_ds)</p>
<p>#数据集中部分可视化<br>
import matplotlib.pyplot as plt<br>
plt.figure(figsize=(8,8))<br>
for n,image_label in enumerate(image_label_ds.take(4)):<br>
plt.subplot(2,2,n+1)<br>
plt.imshow(image_label[0])<br>
plt.grid(False)<br>
plt.xticks([])<br>
plt.yticks([])<br>
plt.show()</p>
<h1 id="下载的模型在用户根目录下~kerasmodelsmobilenet_v2_weights_tf_dim_ordering_tf_kernels_10_192_no_toph5">下载的模型在用户根目录下“~/.keras/models/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_192_no_top.h5”</h1>
<p>mobile_net = tf.keras.applications.MobileNetV2(input_shape=(192, 192, 3),include_top=False)<br>
mobile_net.trainable = False</p>
<h1 id="使用dataset类的shuffle方法打乱数据集">使用Dataset类的shuffle方法打乱数据集</h1>
<p>image_count = len(all_imagine_paths)<br>
ds = image_label_ds.shuffle(buffer_size=image_count)</p>
<h1 id="让数据集重复多次">让数据集重复多次</h1>
<p>ds = ds.repeat()</p>
<h1 id="设置每个batch的大小">设置每个batch的大小</h1>
<p>BATCH_SIZE = 32<br>
ds = ds.batch(BATCH_SIZE)</p>
<h1 id="通过prefetch方法让模型的训练和每个batch数据集的加载并行">通过“prefetch”方法让模型的训练和每个batch数据集的加载并行</h1>
<p>ds = ds.prefetch(buffer_size=AUTOTUNE)</p>
<h1 id="定义一个函数用来将范围在01之间的数据映射到-11之间">定义一个函数用来将范围在[0,1]之间的数据映射到[-1,1]之间</h1>
<p>def change_range(image,label):<br>
return 2*image-1, label</p>
<!-- more -->
<p>keras_ds = ds.map(change_range)<br>
model = tf.keras.Sequential([<br>
mobile_net,<br>
tf.keras.layers.GlobalAveragePooling2D(),<br>
tf.keras.layers.Dense(len(label_names))])</p>
<p>model.compile(optimizer=tf.keras.optimizers.Adam(),<br>
loss='sparse_categorical_crossentropy',<br>
metrics=[&quot;accuracy&quot;])<br>
model.summary()</p>
<p>model.fit(ds, epochs=10, steps_per_epoch=500)</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[神经网络NN]]></title>
        <id>https://www.sssdoctor.com/post/shen-jing-wang-luo-nn/</id>
        <link href="https://www.sssdoctor.com/post/shen-jing-wang-luo-nn/">
        </link>
        <updated>2022-04-01T00:44:28.000Z</updated>
        <summary type="html"><![CDATA[<p>import tensorflow as tf<br>
from keras import layers<br>
#单独的一个输入层<br>
inputs=tf.keras.Input(shape=(32,))<br>
#网络层可以像函数一样被调用</p>
]]></summary>
        <content type="html"><![CDATA[<p>import tensorflow as tf<br>
from keras import layers<br>
#单独的一个输入层<br>
inputs=tf.keras.Input(shape=(32,))<br>
#网络层可以像函数一样被调用</p>
<!-- more -->
<p>x=layers.Dense(64,activation='relu')(inputs)<br>
x=layers.Dense(64,activation='relu')(x)<br>
#输出层<br>
prediction=layers.Dense(10,activation='softmax')(x)<br>
#创建模型<br>
model=tf.keras.Model(inputs=inputs,outputs=prediction)<br>
#编译模型，参数包括指定的优化器，学习率，损失函数loss，metics模型的评价函数  其中adam,sgd都是优化器<br>
model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),<br>
loss='categorical_crossentropy',<br>
metrics=['accuracy'])<br>
#使用numpy生成随机数作为训练数据<br>
import numpy as np<br>
data=np.random.random((1000,32))#1000行32列<br>
labels=np.random.random((1000,10))<br>
print(data[0])<br>
print(labels[0])<br>
#验证集使用numpy随机生成<br>
val_data=np.random.random((1000,32))<br>
val_labels=np.random.random((1000,10))<br>
#模型训练及验证<br>
model.fit(data,labels,epochs=10,batch_size=50,validation_data=(val_data,val_labels))</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[样本类别均衡化及置信概率]]></title>
        <id>https://www.sssdoctor.com/post/yang-ben-lei-bie-jun-heng-hua-ji-zhi-xin-gai-lu/</id>
        <link href="https://www.sssdoctor.com/post/yang-ben-lei-bie-jun-heng-hua-ji-zhi-xin-gai-lu/">
        </link>
        <updated>2022-03-23T01:13:48.000Z</updated>
        <summary type="html"><![CDATA[<p>1.通过类别权重的均衡化，使得占比小的样本权重较高，占比大的样本权重较小，假设100图片，90狗，10猫然后训练出的模型会得出狗的结果，因为这样准确率也能得到90%以上。<br>
API：model=svm.SVC(kernel='linear',calss_weight='balanced')<br>
model.fit(trainx,trainy)</p>
]]></summary>
        <content type="html"><![CDATA[<p>1.通过类别权重的均衡化，使得占比小的样本权重较高，占比大的样本权重较小，假设100图片，90狗，10猫然后训练出的模型会得出狗的结果，因为这样准确率也能得到90%以上。<br>
API：model=svm.SVC(kernel='linear',calss_weight='balanced')<br>
model.fit(trainx,trainy)</p>
<!-- more -->
<p>1.1样本类别不均衡解决方案：上采样、下采样。样本数量2000 类别1 1800   类别2 200<br>
下采样：以数少的为准，减少类别1的数量.<br>
上采样：扩充类别2的数量。</p>
<p>2.置信概率：根据样本与分类边界的距离远近，对其预测类别的可信程度进行量化，离边界越近的样本，置信概率越低，反之，离边界越远的样本，置信概率高。<br>
#API:model=svm.SVC(kernel='rbf',c=600,gamma=0.01,probability=true)#给出超参数：probability=true<br>
#调用model.predict_proba(样本矩阵)<br>
可以获取每个样本的置信概率矩阵</p>
<p>3.网格搜索：获取一个最优超参数的方式可以绘制验证曲线，但是验证曲线只能每次获取一个最优超参数。如果多个超参数有很多排列组合的话们就可以使用网格搜索寻求最优超参数组合。<br>
#API:Model=sklearn.model_selection.GridSearchCV(模型，超参数组合列表，cv=折叠次数)<br>
#model.fit(输入、输出)<br>
#获取网格搜索每个参数组合<br>
#model.cv_results_['params']<br>
#获取网格搜索每个参数组合的平均测试分数<br>
#model.cv_results_['mean_test_score']</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Python中array数组维度]]></title>
        <id>https://www.sssdoctor.com/post/python-zhong-array-shu-zu-wei-du/</id>
        <link href="https://www.sssdoctor.com/post/python-zhong-array-shu-zu-wei-du/">
        </link>
        <updated>2022-03-21T13:16:21.000Z</updated>
        <summary type="html"><![CDATA[<p>X[m,n]<br>
m,n可以看作是行m与列n</p>
]]></summary>
        <content type="html"><![CDATA[<p>X[m,n]<br>
m,n可以看作是行m与列n</p>
<!-- more -->
<p>X[:,0]表示所有行的第一列的元素，X[:,1]表示所有行的第二列元素，X[:,:,0]表示三维数组中第一层（用词可能不当，但是列是二维数组中的），X[:,:,1]表示三维数组中的第二层。需要注意的是X[m,n]表示取值m行中的某一列，然后作为行输出。维度相当于一维。<br>
X[:,m:n]需要单独说一下，表示输出所有行中的某一列到另外N-1列，维度属于二维，有两个【【】】，X[:,:,m:n]同理某一层到另外一层是三维的。<br>
<img src="https://www.sssdoctor.com/post-images/1647871045079.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1647871050707.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1647871055181.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1647871058904.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[决策树]]></title>
        <id>https://www.sssdoctor.com/post/jue-ce-shu/</id>
        <link href="https://www.sssdoctor.com/post/jue-ce-shu/">
        </link>
        <updated>2022-03-18T01:51:09.000Z</updated>
        <content type="html"><![CDATA[<p>1.核心算法：相似的输入产生相似的输出<br>
2.决策树本身就应用了分类的思想，将连续数据离散化。可以提升运算速度。<br>
3.信息熵（混乱程度）。<br>
决策树：sklearn.tree.decidiontreeregressor然后 fit 最后predict<br>
<img src="https://www.sssdoctor.com/post-images/1647912674345.png" alt="" loading="lazy"><br>
4.工程优化：没必要用尽所有特征。可以混杂 最后一级可能数量太少，太片面。优先选择使信息熵减少量最大的特征作为区分的依据。<br>
5.集合算法（算法融合）：根据不同模型给出的预测结果，利用平均（回归）或者分类的方法得出最后的结果。<br>
特征重要性：<br>
6.正向激励（adaboost增强型学习法)：带有权重的树，有点类似于迭代的过程（自适应增强决策树模型），反复构建带有不同权重的树，带有修正（因为有测试集对比）直到达到允许范围内.<br>
正向激励：sklearn.ensemble.adaboostregressor<br>
<img src="https://www.sssdoctor.com/post-images/1647913232195.png" alt="" loading="lazy"><br>
7.自助聚合：有放回随机抽样的方式，行成多颗决策树，提高模型的泛化特性。<br>
8.随机森林：在自助聚合的基础上，对于特征也进行又放回的抽样，行成不同的树，规避不同特征对于模型的影响。<br>
sklearn.ensemble.randomforestregresso<br>
9.特征重要性：feature.importance计算不同特征的信息熵减少量，然后利用柱状图的形式来展现。<br>
<img src="https://www.sssdoctor.com/post-images/1647997113693.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1647997118795.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1647997122746.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[机器学习03—回归]]></title>
        <id>https://www.sssdoctor.com/post/ji-qi-xue-xi-03-xian-xing-hui-gui/</id>
        <link href="https://www.sssdoctor.com/post/ji-qi-xue-xi-03-xian-xing-hui-gui/">
        </link>
        <updated>2022-03-12T00:32:59.000Z</updated>
        <summary type="html"><![CDATA[<p>线性回归：根据已知输入和输出，求解二者之间的线性模型参数，得到连续输入和输出。线性回归的算法种类很多，包括：普通线性回归、岭回归、多项式回归、贝叶斯回归、logistic回归等.</p>
]]></summary>
        <content type="html"><![CDATA[<p>线性回归：根据已知输入和输出，求解二者之间的线性模型参数，得到连续输入和输出。线性回归的算法种类很多，包括：普通线性回归、岭回归、多项式回归、贝叶斯回归、logistic回归等.</p>
<!-- more -->
<p>鉴于目前处于初期学段暂时不做深入探究，暂时介绍三种算法：主要基于sklearn.linear_model.linearrgression、sklearn.linear_model.ridge、sklearn.preprocessing.ploynomia<br>
1.sklearn.linear_model.linearregression<br>
<img src="https://www.sssdoctor.com/post-images/1647873509929.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1647872977323.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1647872996139.png" alt="" loading="lazy"><br>
2.sklearn.linear_model.ridge<br>
<img src="https://www.sssdoctor.com/post-images/1647907809001.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1647907814972.png" alt="" loading="lazy"><br>
3.多项式回归是多元线性回归的一个特例<br>
所以其本质是一个求解多元线性方程组的问题：f(https://www.sssdoctor.com/post-images/1647909151289.png)<br>
左边是关于x的矩阵，右边是关于w系数的矩阵，每一个系数w都对应x中的一列。而PolynomialFeatures就是用来生成关于x的矩阵的。然后再用LinearRegression学习，获得相应的w。需要用到管道和复合估算器pipeline其实就是流水线的意思。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[机器学习数据预处理02]]></title>
        <id>https://www.sssdoctor.com/post/ji-qi-xue-xi-shu-ju-yu-chu-li-02/</id>
        <link href="https://www.sssdoctor.com/post/ji-qi-xue-xi-shu-ju-yu-chu-li-02/">
        </link>
        <updated>2022-03-09T04:21:59.000Z</updated>
        <summary type="html"><![CDATA[<p>手动范围缩放、归一化、独热编码、标签编码</p>
]]></summary>
        <content type="html"><![CDATA[<p>手动范围缩放、归一化、独热编码、标签编码</p>
<!-- more -->
<p>1.手动范围缩放<br>
主要利用一个for循环 （for in遍历转置矩阵，确定最小最大值，根据最大最小值，利用np.linagl.solve(a,b)求解未知数，也就是k,b、然后将求的结果添加到某一空矩阵，继续循环。<br>
<img src="https://www.sssdoctor.com/post-images/1646829755177.png" alt="" loading="lazy"><br>
2.归一化（比例占比100%+1）sp.normalize   norm范数<br>
情景：特征值具体的值不重要、但是每个样本特征值的占比更加重要。示例：不同人对于某一类型的电影与个人观看总体类型的观看比例，可推测偏好相似程度。个人认为数据预处理的方式，跟数据要处理的问题具体相关。<br>
<img src="https://www.sssdoctor.com/post-images/1646829768358.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646829774788.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646829780437.png" alt="" loading="lazy"><br>
3.二值化<br>
有些业务并不需要分析矩阵，完整的数据。比如图像边缘识别只需要检测边缘即可可以根据事先给定的阈值，用0与1表示高不高于阈值。二值化的数组中的每个元素非0即1，需要设置一个阈值器，相当于过滤器，将这一过滤器应用于某一数据组。sp.binarizer(threshold=阈值)然后fit_transform<br>
<img src="https://www.sssdoctor.com/post-images/1646829793035.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646829803227.png" alt="" loading="lazy"><br>
4.独热编码<br>
特征变多，数值的复杂度降低（例如文字）sp.onehotencoder 然后fit_transform<br>
<img src="https://www.sssdoctor.com/post-images/1646829818099.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646829823098.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646829827781.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646829831957.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646829836265.png" alt="" loading="lazy"><br>
5.标签编码<br>
对于某些字符串，利用自带的编码器可以简单编码，但是以后对于自己研究的东西，需要自己写编码的程序<br>
sp.labelencoder()然后fit_transform<br>
<img src="https://www.sssdoctor.com/post-images/1646829856722.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646829862530.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[iCEM 网格划分 练习1]]></title>
        <id>https://www.sssdoctor.com/post/icem-wang-ge-hua-fen-lian-xi-1/</id>
        <link href="https://www.sssdoctor.com/post/icem-wang-ge-hua-fen-lian-xi-1/">
        </link>
        <updated>2022-03-09T01:25:46.000Z</updated>
        <summary type="html"><![CDATA[<p>流场几何形状为45度弯头，内部有一竖直空心管道通过。空心管道与流场接触的壁面对于流体产生阻碍作用。划分的基本操作：1.生成3d块，利用切割功能实现块整体结构与几何的相似。2.关联：快网格能够映射到几何上。3.空心管道进行o型切分，同时删除多余的块。4.进行空心块的关联，包括：边关联以及面关联。5.进行整体结构O型切分。6.划分网格并开始调整。</p>
]]></summary>
        <content type="html"><![CDATA[<p>流场几何形状为45度弯头，内部有一竖直空心管道通过。空心管道与流场接触的壁面对于流体产生阻碍作用。划分的基本操作：1.生成3d块，利用切割功能实现块整体结构与几何的相似。2.关联：快网格能够映射到几何上。3.空心管道进行o型切分，同时删除多余的块。4.进行空心块的关联，包括：边关联以及面关联。5.进行整体结构O型切分。6.划分网格并开始调整。</p>
<!-- more -->
<p><img src="https://www.sssdoctor.com/post-images/1646789517196.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646789525342.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646789530500.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646789534144.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646789538438.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646789553961.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[python—01—学习路径及数据类型]]></title>
        <id>https://www.sssdoctor.com/post/1/</id>
        <link href="https://www.sssdoctor.com/post/1/">
        </link>
        <updated>2022-03-07T06:23:05.000Z</updated>
        <summary type="html"><![CDATA[<p>1.计算机三大件之间的相互关系<br>
cpu负责计算、 内存暂时存储、 硬盘存储，内存相当于中间商，加快cpu需要的数据的输送，硬盘输送数据太慢。<br>
2.变量与内存之间的关系<br>
内存：仓库<br>
变量：仓库内的容器 既然是容器就得有名字、地址、以及空间</p>
]]></summary>
        <content type="html"><![CDATA[<p>1.计算机三大件之间的相互关系<br>
cpu负责计算、 内存暂时存储、 硬盘存储，内存相当于中间商，加快cpu需要的数据的输送，硬盘输送数据太慢。<br>
2.变量与内存之间的关系<br>
内存：仓库<br>
变量：仓库内的容器 既然是容器就得有名字、地址、以及空间</p>
<!-- more -->
<p>3.常量<br>
python里面没有常量、约定俗成是全部大写，但是依然可以修改<br>
<img src="https://www.sssdoctor.com/post-images/1646639742651.png" alt="" loading="lazy"><br>
4.数据类型<br>
4.1引言：<br>
为了计算机方便处理不同的类型<br>
举例:10、中国、#人可以区别 计算机如何区分？<br>
4.2常见类型：<br>
数字类型：int /long/float/<br>
字符串：str存储文字<br>
列表：list<br>
布尔：bool逻辑判断<br>
集合set两组数据之间的关系<br>
字典：dict<br>
字节bytes<br>
4.2.1数字<br>
<img src="https://www.sssdoctor.com/post-images/1646634927872.png" alt="" loading="lazy"></p>
<p>代码：type(变量名)#查看变量类型<br>
python 2.2以后自动将long 转换为Int<br>
4.2.2字符串<br>
只要是引号就可以，但必须保证一致性，三引号表示多行字符串<br>
<img src="https://www.sssdoctor.com/post-images/1646636358317.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646635523316.png" alt="" loading="lazy"><br>
特性一：不可修改<br>
如下图所示，虽然name的显示内容发生改变 但是id地址也发生了改变，原先的id依然存在<br>
<img src="https://www.sssdoctor.com/post-images/1646635631392.png" alt="" loading="lazy"><br>
特性二：有索引，可切片（具有编号）<br>
但是切片是顾头不顾尾，首位为0<br>
<img src="https://www.sssdoctor.com/post-images/1646636119050.png" alt="" loading="lazy"><br>
字符串的格式修改、拼接等操作仍需要扩展！<br>
字符串引用外部变量%s %占位符<br>
注意%d 后面要求是数字<br>
%f后面要求后面是小数<br>
示例：<br>
#方法一</p>
<h2 id="msg-s-info-namesageshobbys">msg='''-------------%s info---------<br>
name:%s<br>
age:%s<br>
hobby:%s</h2>
<p>'''%(name,name,age,hobby)<br>
print(msg)</p>
<h2 id="方法二mdgf-name-info-namenameageagehobbyhobby">#方法二<br>
mdg=f'''-------------{name} info---------<br>
name:{name}<br>
age:{age}<br>
hobby:{hobby}</h2>
<h2 id="printmdg输出-wentao-info-namewentaoage27hobbyswim">'''<br>
print(mdg)<br>
输出：<br>
-------------wentao info---------<br>
name:wentao<br>
age:27<br>
hobby:swim</h2>
<h2 id="-wentao-info-namewentaoage27hobbyswim">-------------wentao info---------<br>
name:wentao<br>
age:27<br>
hobby:swim</h2>
<p>4.2.3bool运算<br>
<img src="https://www.sssdoctor.com/post-images/1646638011085.png" alt="" loading="lazy"><br>
true or false<br>
代码示例：<br>
goal=500<br>
a=600<br>
if goal&gt;=a:<br>
print(&quot;niubi&quot;)<br>
else:<br>
print(&quot;laji&quot;)<br>
输出结果<br>
laji<br>
4.2.4list<br>
可支持多个同等类型字符串并列，以及修改<br>
示例代码：<br>
girl_names=[&quot;xiaobian&quot;,&quot;xiaoyun&quot;,&quot;xiaohei&quot;]</p>
<p>girl_names[1]<br>
print(girl_names[1])<br>
girl_names[0]='hhhh'<br>
print(girl_names)</p>
<p>列表的操作：增、删、改、查<br>
<img src="https://www.sssdoctor.com/post-images/1646639542840.png" alt="" loading="lazy"><br>
示例：<br>
<img src="https://www.sssdoctor.com/post-images/1646641423818.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[机器学习概述]]></title>
        <id>https://www.sssdoctor.com/post/ji-qi-xue-xi/</id>
        <link href="https://www.sssdoctor.com/post/ji-qi-xue-xi/">
        </link>
        <updated>2022-03-01T10:40:17.000Z</updated>
        <summary type="html"><![CDATA[<p>有关机器学习的背景、应用、基本问题以及数据预处理中的均值移除、范围缩放</p>
]]></summary>
        <content type="html"><![CDATA[<p>有关机器学习的背景、应用、基本问题以及数据预处理中的均值移除、范围缩放</p>
<!-- more -->
<p>一、<br>
人工智能<br>
机器学习<br>
深度学习</p>
<p>人工智能领域：computer vision/natural language processing/recommender system) cv/nlp/rc</p>
<p>基础：高等数学（求偏导）、线性代数（会矩阵运算）、概率论与数理统计（随机变量）</p>
<p>二、机器学习的一般过程<br>
<img src="https://www.sssdoctor.com/post-images/1646632942621.jpg" alt="" loading="lazy"><br>
2.1数据处理<br>
2.2机器学习<br>
2.3业务运维</p>
<p>三、应用<br>
股价预测、推荐引擎、人脸识别、语音识别、自然语言识别、图像识别</p>
<p>四、基本问题<br>
4.1回归问题<br>
根据已知的输入输出寻得某一模型，将未知输入带入模型，得到连续的输出<br>
4.2分类问题<br>
根据已知的输入输出寻得某一模型，将未知输入带入模型，得到离散的输出<br>
4.3聚类问题<br>
根据输入的相似程度，将其划分为不同的群落<br>
4.4降维问题<br>
在尽量不影响性能的情况下，降低数据的复杂程度</p>
<p>五、数据预处理<br>
1.输入数据-模型-输出数据<br>
2.一行一样本、一列一特征<br>
3.均值移除（标准化）、范围缩放、归一化、二值化、独热编码、标签编码、<br>
3.1均值移除（标准化）<br>
3.1.1均值为0 标准差为1 可以避免不同特征值的差异对于最后模型性能的影响<br>
此处应该有图<br>
3.1.2标准差能反映数据的离散程度。<br>
import numpy as np #引入numpy库<br>
import sklearn.preprocessing as sp#引入sp库<br>
raw_samples#变量名#=np.array#数组#([<br>
[17,90,4000],<br>
[20,80,5000],<br>
[23,75,5500]])<br>
result=sp.scale(raw_samples)#scale比例模型<br>
print(result)<br>
print(result.mean(axis=0))#mean平均的<br>
print(result.std(axis=0)<br>
)<br>
输出结果为：<br>
[[-1.22474487  1.33630621 -1.33630621]<br>
[ 0.         -0.26726124  0.26726124]<br>
[ 1.22474487 -1.06904497  1.06904497]]<br>
[ 0.00000000e+00 -8.14163551e-16  5.18104078e-16]<br>
[1. 1. 1.]<br>
<img src="https://www.sssdoctor.com/post-images/1646632521860.png" alt="" loading="lazy"></p>
<p>3.2范围缩放<br>
3.2.1将样本矩阵中的每一列最小最大值设为相同的区间，统一各列特征值的范围。一般情况下会把特征值缩放到【0，1】<br>
3.2.2<br>
每个数减去数组中的最小数 结果再除以上一步结果中的最大值<br>
3.2.3<br>
<img src="https://www.sssdoctor.com/post-images/1646630918053.png" alt="" loading="lazy"><br>
import numpy as np<br>
import sklearn.preprocessing as sp</p>
<p>raw_samples=np.array([<br>
[17,90,4000],<br>
[20,80,5000],<br>
[23,75,5500]])<br>
mms=sp.MinMaxScaler(feature_range=(0,1))#MinMaxScaler范围缩放命令（+参数指定）<br>
result=mms.fit_transform(raw_samples)<br>
print(result)<br>
输出结果为：<br>
[[0.         1.         0.        ]<br>
[0.5        0.33333333 0.66666667]<br>
[1.         0.         1.        ]]<br>
<img src="https://www.sssdoctor.com/post-images/1646632838188.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646632844467.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ICEM CFD六面体网格划分-01]]></title>
        <id>https://www.sssdoctor.com/post/icem-cfd-liu-mian-ti-wang-ge-hua-fen/</id>
        <link href="https://www.sssdoctor.com/post/icem-cfd-liu-mian-ti-wang-ge-hua-fen/">
        </link>
        <updated>2022-02-24T01:43:33.000Z</updated>
        <summary type="html"><![CDATA[<p>1.Block基本概念<br>
2.Bolock层次结构<br>
点、线、面、块<br>
3.Block创建(creat)以及分割（split)<br>
3.1自上而下<br>
即先对几何体切块，然后细分，最终实现精细化控制。自上而下实际上是一种拓扑意义上的顺序。常见类型包括：3D、2DSurface、2DPlan</p>
]]></summary>
        <content type="html"><![CDATA[<p>1.Block基本概念<br>
2.Bolock层次结构<br>
点、线、面、块<br>
3.Block创建(creat)以及分割（split)<br>
3.1自上而下<br>
即先对几何体切块，然后细分，最终实现精细化控制。自上而下实际上是一种拓扑意义上的顺序。常见类型包括：3D、2DSurface、2DPlan</p>
<!-- more -->
<p><img src="https://www.sssdoctor.com/post-images/1646649258121.png" alt="" loading="lazy"><br>
3.2自下而上<br>
先建立块的面，然后拉伸块，让块的贴近于几何结构。面块生成以后，自下而上生成块的四个命令才能急活.<br>
总结：关于3d块的关联务必是重点关注的地方，不然软件默认的关联方式会给你带来极大的麻烦。2022.3.08日关于弹簧的网格划分 耗时四五个小时。总结到的最重要的经验就是关联的严谨性<br>
<img src="https://www.sssdoctor.com/post-images/1646649431777.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646723099367.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646723103787.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646723111014.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646723146090.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646723155739.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646723159756.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646723164017.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646723168034.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646723172660.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646723176213.png" alt="" loading="lazy"><br>
3.3普通分割<br>
包括线分割以及点分割，其余切割方式还未接触过。<br>
<img src="https://www.sssdoctor.com/post-images/1646649815800.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646649885776.png" alt="" loading="lazy"><br>
3.4 O型切分的骚操作<br>
适用于圆弧形、比如：圆形、圆柱、球等。O型切分的实质是为映射的实现，提供几何基础，提升映射结构网格的质量。<br>
选择块、面(2d不激活）、边（与边相关的block/face都会被选中，因此L/C切分虽然选择了边，实际上选择了被删除的块）、点。可实现全O型网格、L型、C型网格切分，以及O型外网格切分便于快速创建边界层。<br>
<img src="https://www.sssdoctor.com/post-images/1646652584235.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646653383957.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646653391132.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646653398724.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646653407040.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646653420117.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646653427942.png" alt="" loading="lazy"><br>
3.5Y型切分<br>
3.5.1平面Y型切分<br>
平面三角形的Y切分实际上是四边形的Y切分，因为生成的块是四边形，具体也可参考上部分内容<br>
<img src="https://www.sssdoctor.com/post-images/1646660247248.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646660250473.png" alt="" loading="lazy"><br>
3.5.2 3DY型切分<br>
具体过程：<br>
1.生成块<br>
2.利用合并顶点操作，注意此处要把program去掉勾选（平面三角形不可以用合并点的操作，是因为合并顶点之后块变成三角形，三棱柱则不会，因为还存在四边形）<br>
3.关联边，使得块映射网格能够反映到几何体上<br>
4.移动点，选定相应的约束<br>
5.选择edit block<br>
6.找到对应切面进行Y切分<br>
<img src="https://www.sssdoctor.com/post-images/1646661672859.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646661677674.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646661686488.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646661692169.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646661697459.png" alt="" loading="lazy"><br>
<img src="https://www.sssdoctor.com/post-images/1646661702753.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
</feed>